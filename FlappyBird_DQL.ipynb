{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let DQN play Flappy Bird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flappy bird was a popular game for its high difficulty with an easy-understanding control. What the player needs to do is tapping the screen to make the bird fly higher or doing nothing to drop the bird, in order to let the bird fly over pipes. Though the control is easy, getting good scores is a hard problem. Then training an AI agent who is able to perfectly play this game would be a really interesting project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=“image/FlappyBird.PNG”, width=100, height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our group though it is a great model for us to learn how DQN works, since in this specific game, an agent only has two actions in each state and the description of the state can be simplified as several parameters. That’s might be the reason why so many DQN tutorials use Flappy Bird as the example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Game Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game enviroment, found on github, is a python based Flappy Bird version. The funtion below is the main funtion in this game which is used to update the game state and display the game screen. We have modified the parameters and the return states to accelerate the training process. The return value info is game state in Q Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frame_step(self, input_actions):\n",
    "        pygame.event.pump()\n",
    "\n",
    "        reward = 1.0\n",
    "        terminal = False\n",
    "\n",
    "        # input_actions[0] == 1: do nothing\n",
    "        # input_actions[1] == 1: flap the bird\n",
    "        if input_actions[1] == 1:\n",
    "            if self.playery > -2 * PLAYER_HEIGHT:\n",
    "                self.playerVelY = self.playerFlapAcc\n",
    "                self.playerFlapped = True\n",
    "                #SOUNDS['wing'].play()\n",
    "\n",
    "        # check for score\n",
    "        playerMidPos = self.playerx + PLAYER_WIDTH / 2\n",
    "        for pipe in self.upperPipes:\n",
    "            pipeMidPos = pipe['x'] + PIPE_WIDTH / 2\n",
    "            if pipeMidPos <= playerMidPos < pipeMidPos + 4:\n",
    "                self.score += 1\n",
    "                #SOUNDS['point'].play()\n",
    "                reward = 500\n",
    "\n",
    "        # playerIndex basex change\n",
    "        if (self.loopIter + 1) % 3 == 0:\n",
    "            self.playerIndex = next(PLAYER_INDEX_GEN)\n",
    "        self.loopIter = (self.loopIter + 1) % 30\n",
    "        self.basex = -((-self.basex + 100) % self.baseShift)\n",
    "\n",
    "        # player's movement\n",
    "        if self.playerVelY < self.playerMaxVelY and not self.playerFlapped:\n",
    "            self.playerVelY += self.playerAccY\n",
    "        if self.playerFlapped:\n",
    "            self.playerFlapped = False\n",
    "        self.playery += min(self.playerVelY, BASEY - self.playery - PLAYER_HEIGHT)\n",
    "        if self.playery < 0:\n",
    "            self.playery = 0\n",
    "\n",
    "        # move pipes to left\n",
    "        for uPipe, lPipe in zip(self.upperPipes, self.lowerPipes):\n",
    "            uPipe['x'] += self.pipeVelX\n",
    "            lPipe['x'] += self.pipeVelX\n",
    "\n",
    "        # add new pipe when first pipe is about to touch left of screen\n",
    "        if 0 < self.upperPipes[0]['x'] < 5:\n",
    "            newPipe = getRandomPipe()\n",
    "            self.upperPipes.append(newPipe[0])\n",
    "            self.lowerPipes.append(newPipe[1])\n",
    "\n",
    "        # remove first pipe if its out of the screen\n",
    "        if self.upperPipes[0]['x'] < -PIPE_WIDTH:\n",
    "            self.upperPipes.pop(0)\n",
    "            self.lowerPipes.pop(0)\n",
    "\n",
    "        # check if crash here\n",
    "        isCrash= checkCrash({'x': self.playerx, 'y': self.playery,\n",
    "                             'index': self.playerIndex},\n",
    "                            self.upperPipes, self.lowerPipes)\n",
    "        if isCrash:\n",
    "            #SOUNDS['hit'].play()\n",
    "            #SOUNDS['die'].play()\n",
    "            terminal = True\n",
    "            #reward = - abs(self.playery - self.lowerPipes[0]['y']) /40.0\n",
    "            self.__init__()\n",
    "            reward = -10\n",
    "\n",
    "        FPSCLOCK.tick(FPS)\n",
    "\n",
    "        #print('index = ',self.playerIndex,'playerx = ',self.playerx, 'playery = ',self.playery ,'lowerpipes =', self.lowerPipes[0]['x'])\n",
    "        #print self.upperPipes[0]['y'] + PIPE_HEIGHT - int(BASEY * 0.2)\n",
    "        #return image_data, reward, terminal\n",
    "\n",
    "        info = np.array([self.playery,self.playerAccY, self.playerFlapAcc, self.lowerPipes[0]['x'],self.lowerPipes[0]['y'],self.upperPipes[0]['y']])\n",
    "        return info, reward, terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Design of Deep Q-Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 The structuce of DQN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 The adjust process of Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Trainging Model part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"320\" height=\"240\" controls>\n",
       "  <source src=\"video/Normal_SameHigh.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "  <source src=\"video/Normal_SameHigh.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomPipe():\n",
    "    \"\"\"returns a randomly generated pipe\"\"\"\n",
    "    # y of gap between upper and lower pipe\n",
    "    gapYs = [20, 30, 40, 50, 60, 70, 80, 90]\n",
    "    index = random.randint(0, len(gapYs)-1)\n",
    "    #gapY = gapYs[index]\n",
    "    gapY = gapYs[0]\n",
    "\n",
    "    gapY += int(BASEY * 0.2)\n",
    "    pipeX = SCREENWIDTH + 10\n",
    "\n",
    "    return [\n",
    "        {'x': pipeX, 'y': gapY - PIPE_HEIGHT*1.2},  # upper pipe\n",
    "        {'x': pipeX, 'y': gapY + PIPEGAPSIZE*1.2},  # lower pipe\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we first set the gapY to a constant value. As you can see in the video, all the pipes are at the same height which accelerate the training process. We want to fasten the training process so that we can easily test whether our network comes into effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Training Model part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"320\" height=\"240\" controls>\n",
       "  <source src=\"video/Normal_Random.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"320\" height=\"240\" controls>\n",
    "  <source src=\"video/Normal_Random.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "index = random.randint(0, len(gapYs)-1)  \n",
    "gapY = gapYs[index]  \n",
    "```\n",
    "Here we set the gapY to a random value so in the video you can see the height of the pipes are different. In the previous model, the position of the pipes doesn't matter but here they are important states.   \n",
    "```\n",
    "{'x': pipeX, 'y': gapY - PIPE_HEIGHT*1.2},  \n",
    "{'x': pipeX, 'y': gapY + PIPEGAPSIZE*1.2},  \n",
    "```\n",
    "Considering the time limit, the window size we set is 1.2 times of the initial version. This also accelerate the learning process and we have time to apply different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our game model: https://github.com/floodsung/DRL-FlappyBird/blob/master/game/wrapped_flappy_bird.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
